% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/source_subsel.R
\name{pp_loss_randint}
\alias{pp_loss_randint}
\title{Compute the predictive and empirical cross-validated Mahalanobis loss
under the random intercept model}
\usage{
pp_loss_randint(
  post_y_pred,
  post_lpd,
  post_sigma_e,
  post_sigma_u,
  XX,
  YY,
  indicators,
  post_y_pred_sum = NULL,
  K = 10,
  sir_frac = 0.5
)
}
\arguments{
\item{post_y_pred}{\code{S x m x n} matrix of posterior predictive
at the given \code{XX} covariate values for \code{m} replicates per subject}

\item{post_lpd}{\code{S} evaluations of the log-likelihood computed
at each posterior draw of the parameters}

\item{post_sigma_e}{(\code{nsave}) draws from the posterior distribution
of the observation error SD}

\item{post_sigma_u}{(\code{nsave}) draws from the posterior distribution
of the random intercept SD}

\item{XX}{\code{n x p} matrix of covariates at which to evaluate}

\item{YY}{\code{m x n} matrix of response variables (optional)}

\item{indicators}{\code{L x p} matrix of inclusion indicators (booleans)
where each row denotes a candidate subset}

\item{post_y_pred_sum}{(\code{nsave x n}) matrix of the posterior predictive
draws summed over the replicates within each subject (optional)}

\item{K}{number of cross-validation folds}

\item{sir_frac}{fraction of the posterior samples to use for SIR}
}
\value{
a list with two elements: \code{pred_loss} and \code{emp_loss}
for the predictive and empirical loss, respectively, for each subset.
}
\description{
Use posterior predictive draws and a sampling-importance resampling (SIR)
algorithm to approximate the cross-validated predictive Mahalanobis loss.
The empirical Mahalanobis loss is also returned. The values are computed relative to the "best"
subset according to minimum empirical Mahalanobis loss.
Specifically, these quantities are computed for a collection of
linear models that are fit to the Bayesian model output, where
each linear model features a different subset of predictors.
}
