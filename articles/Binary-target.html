<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="description" content="BayesSubsets">
<title>Targeted Prediction and Binary Outcomes • BayesSubsets</title>
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.2.2/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.2.2/bootstrap.bundle.min.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- bootstrap-toc --><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@v1.0.1/dist/bootstrap-toc.min.js" integrity="sha256-4veVQbu7//Lk5TSmc7YV48MxtMy98e26cf5MrgZYnwo=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- search --><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Targeted Prediction and Binary Outcomes">
<meta property="og:description" content="BayesSubsets">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>
    

    <nav class="navbar fixed-top navbar-light navbar-expand-lg bg-light"><div class="container">
    
    <a class="navbar-brand me-2" href="../index.html">BayesSubsets</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">0.1.0</small>

    
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item">
  <a class="nav-link" href="../articles/BayesSubsets.html">Get started</a>
</li>
<li class="nav-item">
  <a class="nav-link" href="../reference/index.html">Reference</a>
</li>
<li class="active nav-item dropdown">
  <a href="#" class="nav-link dropdown-toggle" data-bs-toggle="dropdown" role="button" aria-expanded="false" aria-haspopup="true" id="dropdown-articles">Articles</a>
  <div class="dropdown-menu" aria-labelledby="dropdown-articles">
    <a class="dropdown-item" href="../articles/Binary-target.html">Targeted Prediction and Binary Outcomes</a>
    <a class="dropdown-item" href="../articles/High-dim.html">BayesSubsets with high-dimensional data</a>
  </div>
</li>
      </ul>
<form class="form-inline my-2 my-lg-0" role="search">
        <input type="search" class="form-control me-sm-2" aria-label="Toggle navigation" name="search-input" data-search-index="../search.json" id="search-input" placeholder="Search for" autocomplete="off">
</form>

      <ul class="navbar-nav">
<li class="nav-item">
  <a class="external-link nav-link" href="https://github.com/drkowal/BayesSubsets/" aria-label="github">
    <span class="fab fa fab fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
</div>

    
  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="" class="logo" alt=""><h1>Targeted Prediction and Binary Outcomes</h1>
            
      
      <small class="dont-index">Source: <a href="https://github.com/drkowal/BayesSubsets/blob/HEAD/vignettes/Binary-target.Rmd" class="external-link"><code>vignettes/Binary-target.Rmd</code></a></small>
      <div class="d-none name"><code>Binary-target.Rmd</code></div>
    </div>

    
    
<div class="section level2">
<h2 id="targeted-prediction">Targeted prediction<a class="anchor" aria-label="anchor" href="#targeted-prediction"></a>
</h2>
<p>Given a regression model <span class="math inline">\(M\)</span> for
data <span class="math inline">\((X, y)\)</span>, it is often a priority
to <em>summarize</em> (or interpret) <span class="math inline">\(M\)</span>. Further, the primary decision task or
scientific inquiry is frequently described by a <em>functional</em>
<span class="math inline">\(h(y)\)</span>, such as exceedance of a
threshold. <strong>Targeted prediction</strong> customizes the
summarization of <span class="math inline">\(M\)</span> specifically for
<span class="math inline">\(h\)</span>, including linear coefficient
estimates/intervals and subset selection <a href="https://doi.org/10.1080/01621459.2021.1891926" class="external-link">(Kowal, 2021)</a>.
This is achieved using Bayesian decision analysis for <span class="math inline">\(h(\tilde{y})\)</span>, where <span class="math inline">\(\tilde{y}\)</span> is a posterior predictive
variable under <span class="math inline">\(M\)</span>.</p>
<p>There are several reasons to use targeted prediction:</p>
<ul>
<li><p>We can summarize <span class="math inline">\(M\)</span> for
multiple functionals <span class="math inline">\(h_1, h_2,
\ldots\)</span> <em>without</em> refitting the model for each <span class="math inline">\(h_k\)</span>;</p></li>
<li><p>The model <span class="math inline">\(M\)</span> provides
regularization for <span class="math inline">\(\tilde{y}\)</span> and
thus <span class="math inline">\(h(\tilde{y})\)</span>, which offers
downstream benefits for point/interval estimation and selection (e.g.,
if <span class="math inline">\(y\)</span> is functional data and <span class="math inline">\(h\)</span> is the maximum; see <a href="https://doi.org/10.1080/01621459.2021.1891926" class="external-link">Kowal, 2021</a> for
examples); and</p></li>
<li><p>More generally, the functional may be written <span class="math inline">\(h(\theta, \tilde{y})\)</span> for model <span class="math inline">\(M\)</span> parameters <span class="math inline">\(\theta\)</span>, and thus depends on unobservables
(and so cannot be computed directly from the data <span class="math inline">\(y\)</span>).</p></li>
</ul>
</div>
<div class="section level2">
<h2 id="binary-outcomes">Binary outcomes<a class="anchor" aria-label="anchor" href="#binary-outcomes"></a>
</h2>
<p>We will focus on binary functionals <span class="math inline">\(h:\mathbb{R}\to \{0,1\}\)</span>, so that <span class="math inline">\(h(\tilde{y})\)</span> and <span class="math inline">\(h(y)\)</span> are <strong>binary</strong>. Thus,
this example will also highlight the capabilities of
<code>BayesSubsets</code> for binary outcomes. Specifically, the
decision analysis requires a choice of a loss function. Implementations
are available for both <em>cross-entropy</em> loss and
<em>misclassification rate</em>; we will focus on the former.</p>
</div>
<div class="section level2">
<h2 id="getting-started">Getting started<a class="anchor" aria-label="anchor" href="#getting-started"></a>
</h2>
<p>We begin by installing and loading the package:</p>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># devtools::install_github("drkowal/BayesSubsets")</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/drkowal/BayesSubsets" class="external-link">BayesSubsets</a></span><span class="op">)</span></span></code></pre></div>
<p>For this example, we will consider simulated data with correlated
covariates <span class="math inline">\(X\)</span> and a continuous
outcome <span class="math inline">\(y \in \mathbb{R}\)</span>:</p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># To reproduce:</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Random.html" class="external-link">set.seed</a></span><span class="op">(</span><span class="fl">123</span><span class="op">)</span> </span>
<span></span>
<span><span class="co"># Simulate some data:</span></span>
<span><span class="va">dat</span> <span class="op">=</span> <span class="fu"><a href="../reference/simulate_lm.html">simulate_lm</a></span><span class="op">(</span>n <span class="op">=</span> <span class="fl">200</span>,   <span class="co"># number of observations</span></span>
<span>                  p <span class="op">=</span> <span class="fl">10</span>,    <span class="co"># number of predictors</span></span>
<span>                  p_sig <span class="op">=</span> <span class="fl">5</span>, <span class="co"># number of true signals</span></span>
<span>                  SNR <span class="op">=</span> <span class="fl">1</span>    <span class="co"># signal-to-noise ratio</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Store the data:</span></span>
<span><span class="va">y</span> <span class="op">=</span> <span class="va">dat</span><span class="op">$</span><span class="va">y</span>; <span class="va">X</span> <span class="op">=</span> <span class="va">dat</span><span class="op">$</span><span class="va">X</span></span></code></pre></div>
<p>Next, we fit a Bayesian linear model. The output from
<code>bayeslm</code> does not include posterior predictive draws or
log-predictive density evaluations, so we compute those as well.</p>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Package for efficient Bayesian linear regression:</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/JingyuHe/bayeslm" class="external-link">bayeslm</a></span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Fit the Bayesian regression model:</span></span>
<span><span class="va">fit</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/pkg/bayeslm/man/bayeslm.html" class="external-link">bayeslm</a></span><span class="op">(</span><span class="va">y</span> <span class="op">~</span> <span class="va">X</span><span class="op">[</span>,<span class="op">-</span><span class="fl">1</span><span class="op">]</span>, <span class="co"># intercept already included</span></span>
<span>              N <span class="op">=</span> <span class="fl">10000</span>, <span class="co"># MCMC samples to save</span></span>
<span>              burnin <span class="op">=</span> <span class="fl">5000</span> <span class="co"># initial samples to discard</span></span>
<span><span class="op">)</span></span>
<span><span class="co">#&gt; horseshoe prior </span></span>
<span><span class="co">#&gt; fixed running time 0.00209821</span></span>
<span><span class="co">#&gt; sampling time 0.210797</span></span>
<span></span>
<span><span class="co"># Extract the posterior predictive draws and lpd:</span></span>
<span><span class="va">temp</span> <span class="op">=</span> <span class="fu"><a href="../reference/post_predict.html">post_predict</a></span><span class="op">(</span>post_y_hat <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/crossprod.html" class="external-link">tcrossprod</a></span><span class="op">(</span><span class="va">fit</span><span class="op">$</span><span class="va">beta</span>, <span class="va">X</span><span class="op">)</span>,</span>
<span>                    post_sigma <span class="op">=</span> <span class="va">fit</span><span class="op">$</span><span class="va">sigma</span>,</span>
<span>                    yy <span class="op">=</span> <span class="va">y</span><span class="op">)</span></span>
<span><span class="va">post_y_pred</span> <span class="op">=</span> <span class="va">temp</span><span class="op">$</span><span class="va">post_y_pred</span></span>
<span><span class="va">post_lpd</span> <span class="op">=</span> <span class="va">temp</span><span class="op">$</span><span class="va">post_lpd</span></span></code></pre></div>
<p>To this point, there is no mention of the functional <span class="math inline">\(h\)</span>: we observed data <span class="math inline">\((X, y)\)</span> and fit a Bayesian model <span class="math inline">\(M\)</span>. Importantly, we can define many
different options for <span class="math inline">\(h\)</span> from this
point forward, without the need to refit <span class="math inline">\(M\)</span>.</p>
</div>
<div class="section level2">
<h2 id="defining-the-functional">Defining the functional<a class="anchor" aria-label="anchor" href="#defining-the-functional"></a>
</h2>
<p>We will define <span class="math inline">\(h\)</span> as the
exceedance of a threshold: <span class="math display">\[
h(t) = 1(t \ge \tau)
\]</span> where <span class="math inline">\(\tau\)</span> is specified
in advance. We will fix <span class="math inline">\(\tau\)</span> at the
90th quantile:</p>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">tau</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/quantile.html" class="external-link">quantile</a></span><span class="op">(</span><span class="va">y</span>, <span class="fl">0.9</span><span class="op">)</span></span>
<span><span class="va">h</span> <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">t</span><span class="op">)</span><span class="op">{</span></span>
<span>  <span class="fl">1.0</span><span class="op">*</span><span class="fu"><a href="https://rdrr.io/r/base/AsIs.html" class="external-link">I</a></span><span class="op">(</span><span class="va">t</span> <span class="op">&gt;=</span> <span class="va">tau</span><span class="op">)</span></span>
<span><span class="op">}</span></span></code></pre></div>
<p>The critical term is the posterior predictive distribution of <span class="math inline">\(h(\tilde{y})\)</span>, and its expectation. This
is easy to compute:</p>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Posterior predictive draws of h:</span></span>
<span><span class="va">post_h_pred</span> <span class="op">=</span> <span class="fu">h</span><span class="op">(</span><span class="va">post_y_pred</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Fitted values:</span></span>
<span><span class="va">h_bar</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/colSums.html" class="external-link">colMeans</a></span><span class="op">(</span><span class="va">post_h_pred</span><span class="op">)</span></span></code></pre></div>
<p>A subtle yet important point is that these fitted values <span class="math inline">\(\bar{h} = \mathbb{E}\{h(\tilde{y}) | y\} \in
[0,1]\)</span> are <em>continuous</em>, while <span class="math inline">\(h(y) \in \{0,1\}\)</span> are binary. For a
well-specified model <span class="math inline">\(M\)</span>, <span class="math inline">\(\bar{h}\)</span> may be more informative than
<span class="math inline">\(h(y)\)</span> because it lies along a
continuum.</p>
</div>
<div class="section level2">
<h2 id="computing-optimal-linear-coefficients">Computing optimal linear coefficients<a class="anchor" aria-label="anchor" href="#computing-optimal-linear-coefficients"></a>
</h2>
<p>Given any Bayesian regression model <span class="math inline">\(M\)</span> and any subset of covariates <span class="math inline">\(S\)</span>, we compute the <strong>optimal linear
coefficients</strong> according to Bayesian decision analysis. <a href="https://doi.org/10.1080/01621459.2021.1891926" class="external-link">Kowal (2021)</a>
showed that the coefficients can be computed (under cross-entropy loss)
using “fit-to-the-fit”, and specifically a logistic regression model
with response <span class="math inline">\(\bar{h}\)</span> and
covariates <span class="math inline">\(X_S\)</span>, i.e., the covariate
matrix <span class="math inline">\(X\)</span> restricted to the columns
selected in <span class="math inline">\(S\)</span>. For an example
subset <span class="math inline">\(S = \{1,3,10\}\)</span> and
cross-entropy loss, the following code computes our optimal linear
summary:</p>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Example subset:</span></span>
<span><span class="va">S_ex</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">3</span>, <span class="fl">10</span><span class="op">)</span> </span>
<span></span>
<span><span class="co"># Optimal coefficients:</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/coef.html" class="external-link">coef</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/glm.html" class="external-link">glm</a></span><span class="op">(</span><span class="va">h_bar</span> <span class="op">~</span> <span class="va">X</span><span class="op">[</span>,<span class="va">S_ex</span><span class="op">]</span> <span class="op">-</span> <span class="fl">1</span><span class="op">)</span>, family <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/family.html" class="external-link">binomial</a></span><span class="op">(</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt;  X[, S_ex]X1  X[, S_ex]X3 X[, S_ex]X10 </span></span>
<span><span class="co">#&gt;   0.11654316   0.11131220  -0.02752669</span></span></code></pre></div>
</div>
<div class="section level2">
<h2 id="uncertainty-quantification-for-the-linear-coefficients">Uncertainty quantification for the linear coefficients<a class="anchor" aria-label="anchor" href="#uncertainty-quantification-for-the-linear-coefficients"></a>
</h2>
<p>We may also obtain posterior uncertainty quantification for the
linear coefficients that are active (nonzero) in <span class="math inline">\(S\)</span>. To do so, we compute the same logistic
regression for each posterior predictive draw of <span class="math inline">\(h(\tilde{y})\)</span>, which induces a posterior
predictive distribution for the linear coefficients under the model
<span class="math inline">\(M\)</span>—even though <span class="math inline">\(M\)</span> is not a model for binary data. We
summarize those posteriors using 95% credible intervals.</p>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Posterior predictive draws of *all* coefficients:</span></span>
<span><span class="va">sub_sims</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/sample.html" class="external-link">sample</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html" class="external-link">nrow</a></span><span class="op">(</span><span class="va">post_h_pred</span><span class="op">)</span>, <span class="fl">1000</span><span class="op">)</span> <span class="co"># just use 1000 draws</span></span>
<span><span class="va">post_beta_s</span> <span class="op">=</span> <span class="fu"><a href="../reference/proj_posterior.html">proj_posterior</a></span><span class="op">(</span>post_y_pred <span class="op">=</span> <span class="va">post_h_pred</span><span class="op">[</span><span class="va">sub_sims</span>,<span class="op">]</span>, </span>
<span>                             XX <span class="op">=</span> <span class="va">X</span>,</span>
<span>                             sub_x <span class="op">=</span> <span class="va">S_ex</span>,</span>
<span>                             use_ols <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/dim.html" class="external-link">dim</a></span><span class="op">(</span><span class="va">post_beta_s</span><span class="op">)</span> <span class="co"># the coefficients outside S_ex are fixed at zero</span></span>
<span><span class="co">#&gt; [1] 1000   11</span></span>
<span></span>
<span><span class="co"># Compute 95% credible intervals for the nonzero entries:</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/t.html" class="external-link">t</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/apply.html" class="external-link">apply</a></span><span class="op">(</span><span class="va">post_beta_s</span><span class="op">[</span>,<span class="va">S_ex</span><span class="op">]</span>, <span class="fl">2</span>, </span>
<span>        <span class="va">quantile</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">0.05</span><span class="op">/</span><span class="fl">2</span>, <span class="fl">1</span> <span class="op">-</span> <span class="fl">0.05</span><span class="op">/</span><span class="fl">2</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt;           2.5%      97.5%</span></span>
<span><span class="co">#&gt; X1  -3.2129778 -1.8746403</span></span>
<span><span class="co">#&gt; X3   0.6244174  2.2529052</span></span>
<span><span class="co">#&gt; X10 -0.9761212  0.2704743</span></span></code></pre></div>
</div>
<div class="section level2">
<h2 id="bayesian-subset-search">Bayesian subset search<a class="anchor" aria-label="anchor" href="#bayesian-subset-search"></a>
</h2>
<p>To search across candidate subsets, we use a branch-and-bound
algorithm with a weighted least squares approximation to the
cross-entropy loss. This approximation uses the logit of <span class="math inline">\(\bar{h}\)</span> as the response and <span class="math inline">\(\bar{h}(1 - \bar{h})\)</span> as the weights. For
small <span class="math inline">\(p\)</span> it may be possible to
enumerate all possible subsets. Here, we screen to the “best”
<code>n_best = 50</code> models of each size according to squared error
loss. We store these in a Boolean matrix <code>indicators</code>: each
row is an individual subset, while the columns indicate which variables
are included (<code>TRUE</code>) or excluded (<code>FALSE</code>). We
also check to make sure that <span class="math inline">\(\bar{h} \ne
0\)</span> and <span class="math inline">\(\bar{h} \ne 1\)</span>, which
can occur numerically and creates problems for the logit call.</p>
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span></span>
<span><span class="co"># Make sure we do not have any zeros or ones:</span></span>
<span><span class="va">h_bar</span><span class="op">[</span><span class="va">h_bar</span> <span class="op">==</span> <span class="fl">0</span><span class="op">]</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/Extremes.html" class="external-link">min</a></span><span class="op">(</span><span class="va">h_bar</span><span class="op">[</span><span class="va">h_bar</span> <span class="op">!=</span> <span class="fl">0</span><span class="op">]</span><span class="op">)</span> <span class="co"># set to the non-zero min</span></span>
<span><span class="va">h_bar</span><span class="op">[</span><span class="va">h_bar</span> <span class="op">==</span> <span class="fl">1</span><span class="op">]</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/Extremes.html" class="external-link">max</a></span><span class="op">(</span><span class="va">h_bar</span><span class="op">[</span><span class="va">h_bar</span> <span class="op">!=</span> <span class="fl">1</span><span class="op">]</span><span class="op">)</span> <span class="co"># set to the non-one max</span></span>
<span></span>
<span><span class="va">indicators</span> <span class="op">=</span> <span class="fu"><a href="../reference/branch_and_bound.html">branch_and_bound</a></span><span class="op">(</span>yy <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html" class="external-link">log</a></span><span class="op">(</span><span class="va">h_bar</span><span class="op">/</span><span class="op">(</span><span class="fl">1</span> <span class="op">-</span> <span class="va">h_bar</span><span class="op">)</span><span class="op">)</span>, <span class="co"># response is the logit of h_bar</span></span>
<span>                             XX <span class="op">=</span> <span class="va">X</span>,            <span class="co"># covariates</span></span>
<span>                             wts <span class="op">=</span> <span class="va">h_bar</span><span class="op">*</span><span class="op">(</span><span class="fl">1</span> <span class="op">-</span> <span class="va">h_bar</span><span class="op">)</span>, <span class="co"># weights for weighted least squares</span></span>
<span>                             n_best <span class="op">=</span> <span class="fl">50</span>        <span class="co"># restrict to the "best" 50 subsets of each size</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Inspect:</span></span>
<span><span class="va">indicators</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fl">5</span>, <span class="fl">1</span><span class="op">:</span><span class="fl">10</span><span class="op">]</span></span>
<span><span class="co">#&gt;            X1    X2    X3    X4    X5    X6    X7    X8    X9   X10</span></span>
<span><span class="co">#&gt; force_in TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE</span></span>
<span><span class="co">#&gt;          TRUE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE</span></span>
<span><span class="co">#&gt;          TRUE FALSE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE</span></span>
<span><span class="co">#&gt;          TRUE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE</span></span>
<span><span class="co">#&gt;          TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE  TRUE FALSE</span></span>
<span></span>
<span><span class="co"># Dimensions:</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/dim.html" class="external-link">dim</a></span><span class="op">(</span><span class="va">indicators</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] 362  11</span></span>
<span></span>
<span><span class="co"># Summarize the model sizes:</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/table.html" class="external-link">table</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/colSums.html" class="external-link">rowSums</a></span><span class="op">(</span><span class="va">indicators</span><span class="op">)</span><span class="op">)</span> <span class="co"># note: intercept always included</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;  1  2  3  4  5  6  7  8  9 10 11 </span></span>
<span><span class="co">#&gt;  1 10 45 50 50 50 50 50 45 10  1</span></span></code></pre></div>
</div>
<div class="section level2">
<h2 id="the-acceptable-family-of-near-optimal-subsets">The acceptable family of “near-optimal” subsets<a class="anchor" aria-label="anchor" href="#the-acceptable-family-of-near-optimal-subsets"></a>
</h2>
<p>From this large collection of 362 candidate subsets, we seek to
filter to the <strong>acceptable family</strong> of subsets, i.e., those
“near-optimal” subsets that predict about as well as the “best” subset.
These are computed based on 10-fold cross-validation, and use the
out-of-sample predictive distribution from <span class="math inline">\(M\)</span> to provide uncertainty quantification
for predictive accuracy.</p>
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Compute the acceptable family:</span></span>
<span><span class="va">accept_info</span> <span class="op">=</span> <span class="fu"><a href="../reference/accept_family_binary.html">accept_family_binary</a></span><span class="op">(</span>post_y_pred <span class="op">=</span> <span class="va">post_h_pred</span>,</span>
<span>                                   post_lpd <span class="op">=</span> <span class="va">post_lpd</span>,</span>
<span>                                   XX <span class="op">=</span> <span class="va">X</span>,</span>
<span>                                   indicators <span class="op">=</span> <span class="va">indicators</span>,</span>
<span>                                   loss_type <span class="op">=</span> <span class="st">"cross-ent"</span>,</span>
<span>                                   yy <span class="op">=</span> <span class="fu">h</span><span class="op">(</span><span class="va">y</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<p><img src="Binary-target_files/figure-html/accept-1.png" width="576"></p>
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span></span>
<span><span class="co"># How many subsets are in the acceptable family?</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/length.html" class="external-link">length</a></span><span class="op">(</span><span class="va">accept_info</span><span class="op">$</span><span class="va">all_accept</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] 257</span></span>
<span></span>
<span><span class="co"># These are the rows of `indicators` that belong to the acceptable family:</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/head.html" class="external-link">head</a></span><span class="op">(</span><span class="va">accept_info</span><span class="op">$</span><span class="va">all_accept</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] 57 58 59 60 63 64</span></span>
<span></span>
<span><span class="co"># An example acceptable subset:</span></span>
<span><span class="va">ex_accept</span> <span class="op">=</span> <span class="va">accept_info</span><span class="op">$</span><span class="va">all_accept</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/which.html" class="external-link">which</a></span><span class="op">(</span><span class="va">indicators</span><span class="op">[</span><span class="va">ex_accept</span>,<span class="op">]</span><span class="op">)</span></span>
<span><span class="co">#&gt; X1 X2 X5 X6 </span></span>
<span><span class="co">#&gt;  1  2  5  6</span></span></code></pre></div>
<p>The plot shows how the out-of-sample predictive performance varies
across subsets of different sizes, specifically relative (% change) to
the “best” subset (by minimum cross-validated error; dashed gray
vertical line). The x-marks are the (usual) empirical cross-validated
error, while the intervals leverage the predictive distribution from
<span class="math inline">\(M\)</span> to quantify uncertainty in the
out-of-sample predictive performance. While performance improves as
variables are added, it is clear that several smaller subsets are highly
competitive—especially when accounting for the predictive
uncertainty.</p>
</div>
<div class="section level2">
<h2 id="subset-selection-the-smallest-acceptable-subset">Subset selection: the smallest acceptable subset<a class="anchor" aria-label="anchor" href="#subset-selection-the-smallest-acceptable-subset"></a>
</h2>
<p>If we wish to <strong>select</strong> a single subset, a compelling
representative of the acceptable family is the <strong>smallest</strong>
acceptable subset. This choice favors parsimony, while its membership in
the acceptable family implies that it meets a high standard for
predictive accuracy. From the previous plot, we select the smallest
subset for which the intervals include zero (solid gray vertical
line).</p>
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Simplest acceptable subset:</span></span>
<span><span class="va">beta_hat_small</span> <span class="op">=</span> <span class="va">accept_info</span><span class="op">$</span><span class="va">beta_hat_small</span></span>
<span></span>
<span><span class="co"># Which coefficients are nonzero:</span></span>
<span><span class="va">S_small</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/which.html" class="external-link">which</a></span><span class="op">(</span><span class="va">beta_hat_small</span> <span class="op">!=</span> <span class="fl">0</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># How many coefficients are nonzero:</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/length.html" class="external-link">length</a></span><span class="op">(</span><span class="va">S_small</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] 4</span></span></code></pre></div>
<p>We can obtain posterior samples and credible intervals for the
coefficients as before:</p>
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Draws from the posterior predictive distribution</span></span>
<span><span class="va">post_beta_small</span> <span class="op">=</span> <span class="fu"><a href="../reference/proj_posterior.html">proj_posterior</a></span><span class="op">(</span>post_y_pred <span class="op">=</span> <span class="va">post_h_pred</span><span class="op">[</span><span class="va">sub_sims</span>,<span class="op">]</span>, <span class="co"># just use 1000 draws</span></span>
<span>                                 XX <span class="op">=</span> <span class="va">X</span>,</span>
<span>                                 sub_x <span class="op">=</span> <span class="va">S_small</span>,</span>
<span>                                 use_ols <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Compute 95% credible intervals for the nonzero entries:</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/t.html" class="external-link">t</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/apply.html" class="external-link">apply</a></span><span class="op">(</span><span class="va">post_beta_small</span><span class="op">[</span>,<span class="va">S_small</span><span class="op">]</span>, <span class="fl">2</span>, </span>
<span>        <span class="va">quantile</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">0.05</span><span class="op">/</span><span class="fl">2</span>, <span class="fl">1</span> <span class="op">-</span> <span class="fl">0.05</span><span class="op">/</span><span class="fl">2</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt;         2.5%       97.5%</span></span>
<span><span class="co">#&gt; X1 -3.711372 -2.01259590</span></span>
<span><span class="co">#&gt; X2  1.019795  2.73711706</span></span>
<span><span class="co">#&gt; X5 -1.289039 -0.08855023</span></span>
<span><span class="co">#&gt; X6 -1.497176 -0.06492849</span></span></code></pre></div>
</div>
<div class="section level2">
<h2 id="variable-importance-from-acceptable-subsets">Variable importance from acceptable subsets<a class="anchor" aria-label="anchor" href="#variable-importance-from-acceptable-subsets"></a>
</h2>
<p>Another useful summary of the acceptable family is the
<strong>variable importance</strong>, which reports, for each variable
<span class="math inline">\(j\)</span>, the proportion of acceptable
subsets in which <span class="math inline">\(j\)</span> appears. We are
particularly interested in distinguishing among those variables that
occur in <em>all</em>, <em>some</em>, or <em>no</em> acceptable subsets,
which provides insight about which variables are indispensable
(“keystone covariates”) and which variables are part of a “predictively
plausible” explanation.</p>
<div class="sourceCode" id="cb13"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Variable importance: proportion of *acceptable subsets* in which each variable appears</span></span>
<span><span class="va">vi_e</span> <span class="op">=</span> <span class="fu"><a href="../reference/var_imp.html">var_imp</a></span><span class="op">(</span>indicators <span class="op">=</span> <span class="va">indicators</span>,</span>
<span>               all_accept <span class="op">=</span> <span class="va">accept_info</span><span class="op">$</span><span class="va">all_accept</span><span class="op">)</span><span class="op">$</span><span class="va">vi_inc</span></span>
<span></span>
<span><span class="co"># "Keystone covariates" that appear in *all* acceptable families:</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/which.html" class="external-link">which</a></span><span class="op">(</span><span class="va">vi_e</span> <span class="op">==</span> <span class="fl">1</span><span class="op">)</span></span>
<span><span class="co">#&gt; 1 </span></span>
<span><span class="co">#&gt; 1</span></span>
<span></span>
<span><span class="co"># Irrelevant covariates that appear in *no* acceptable families:</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/which.html" class="external-link">which</a></span><span class="op">(</span><span class="va">vi_e</span> <span class="op">==</span> <span class="fl">0</span><span class="op">)</span> </span>
<span><span class="co">#&gt; named integer(0)</span></span>
<span></span>
<span><span class="co"># Visualize:</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/barplot.html" class="external-link">barplot</a></span><span class="op">(</span><span class="va">vi_e</span><span class="op">[</span><span class="fu"><a href="https://rdrr.io/r/base/order.html" class="external-link">order</a></span><span class="op">(</span><span class="va">vi_e</span>, <span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html" class="external-link">ncol</a></span><span class="op">(</span><span class="va">X</span><span class="op">)</span><span class="op">:</span><span class="fl">1</span><span class="op">)</span><span class="op">)</span><span class="op">]</span>, <span class="co"># order...</span></span>
<span>        horiz <span class="op">=</span> <span class="cn">TRUE</span>, </span>
<span>        main <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/paste.html" class="external-link">paste</a></span><span class="op">(</span><span class="st">'Variable importance for the acceptable family'</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/abline.html" class="external-link">abline</a></span><span class="op">(</span>v <span class="op">=</span> <span class="fl">1</span><span class="op">)</span></span></code></pre></div>
<p><img src="Binary-target_files/figure-html/vi-1.png" width="576"></p>
<p>Most variables belong to some, but not all, acceptable subsets.</p>
</div>
<div class="section level2">
<h2 id="conclusions">Conclusions<a class="anchor" aria-label="anchor" href="#conclusions"></a>
</h2>
<p>Even for various functionals <span class="math inline">\(h\)</span>
and/or binary outcomes, the pipeline is nearly identical to the simpler
continuous outcome case. For binary outcomes, the code is moderately
slower: repeated evaluations of <code>glm</code> are less efficient than
<code>lm</code>, and these are needed for 1) posterior predictive
uncertainty quantification via <code>proj_posterior</code> (with
<code>use_ols = FALSE</code>) and 2) predictive evaluation to construct
the acceptable family via <code>accept_family_binary</code>. However,
there is no need to refit <span class="math inline">\(M\)</span> for
different choices of <span class="math inline">\(h\)</span> (e.g.,
varying the threshold <span class="math inline">\(\tau\)</span>), which
can be a substantial time-saver when <span class="math inline">\(M\)</span> is complex (e.g, a functional data
regression model). Finally, we note that if <span class="math inline">\(M\)</span> is a binary regression model and <span class="math inline">\(h(t) = t\)</span> is unnecessary, then we can
replace <code>post_h_pred</code> with <code>post_y_pred</code>
throughout (and <code>y</code> simply replaces <code>h(y)</code>).</p>
</div>
  </main><aside class="col-md-3"><nav id="toc"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p></p>
<p>Developed by Dan Kowal.</p>
</div>

<div class="pkgdown-footer-right">
  <p></p>
<p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.0.7.</p>
</div>

    </footer>
</div>

  

  

  </body>
</html>
