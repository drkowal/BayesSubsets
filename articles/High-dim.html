<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="description" content="BayesSubsets">
<title>BayesSubsets with high-dimensional data • BayesSubsets</title>
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.2.2/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.2.2/bootstrap.bundle.min.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- bootstrap-toc --><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@v1.0.1/dist/bootstrap-toc.min.js" integrity="sha256-4veVQbu7//Lk5TSmc7YV48MxtMy98e26cf5MrgZYnwo=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- search --><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="BayesSubsets with high-dimensional data">
<meta property="og:description" content="BayesSubsets">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>
    

    <nav class="navbar fixed-top navbar-light navbar-expand-lg bg-light"><div class="container">
    
    <a class="navbar-brand me-2" href="../index.html">BayesSubsets</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">0.1.0</small>

    
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item">
  <a class="nav-link" href="../articles/BayesSubsets.html">Get started</a>
</li>
<li class="nav-item">
  <a class="nav-link" href="../reference/index.html">Reference</a>
</li>
<li class="active nav-item dropdown">
  <a href="#" class="nav-link dropdown-toggle" data-bs-toggle="dropdown" role="button" aria-expanded="false" aria-haspopup="true" id="dropdown-articles">Articles</a>
  <div class="dropdown-menu" aria-labelledby="dropdown-articles">
    <a class="dropdown-item" href="../articles/Binary-target.html">Targeted Prediction and Binary Outcomes</a>
    <a class="dropdown-item" href="../articles/High-dim.html">BayesSubsets with high-dimensional data</a>
  </div>
</li>
      </ul>
<form class="form-inline my-2 my-lg-0" role="search">
        <input type="search" class="form-control me-sm-2" aria-label="Toggle navigation" name="search-input" data-search-index="../search.json" id="search-input" placeholder="Search for" autocomplete="off">
</form>

      <ul class="navbar-nav">
<li class="nav-item">
  <a class="external-link nav-link" href="https://github.com/drkowal/BayesSubsets/" aria-label="github">
    <span class="fab fa fab fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
</div>

    
  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="" class="logo" alt=""><h1>BayesSubsets with high-dimensional data</h1>
            
      
      <small class="dont-index">Source: <a href="https://github.com/drkowal/BayesSubsets/blob/HEAD/vignettes/High-dim.Rmd" class="external-link"><code>vignettes/High-dim.Rmd</code></a></small>
      <div class="d-none name"><code>High-dim.Rmd</code></div>
    </div>

    
    
<div class="section level2">
<h2 id="high-dimensional-data">High-dimensional data<a class="anchor" aria-label="anchor" href="#high-dimensional-data"></a>
</h2>
<p>This document revisits <code>BayesSubsets</code> for subset search,
selection, and summarization. In particular, we consider the case where
<span class="math inline">\(p &gt; n\)</span> and <span class="math inline">\(p = 400\)</span> is large. This is traditionally
infeasible for subset selection, so we describe the pre-screening tools
that we deploy in order to apply <code>BayesSubsets</code>.</p>
</div>
<div class="section level2">
<h2 id="getting-started">Getting started<a class="anchor" aria-label="anchor" href="#getting-started"></a>
</h2>
<p>We begin by installing and loading the package:</p>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># devtools::install_github("drkowal/BayesSubsets")</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/drkowal/BayesSubsets" class="external-link">BayesSubsets</a></span><span class="op">)</span></span></code></pre></div>
<p>For this example, we will consider simulated data with correlated
covariates <span class="math inline">\(X\)</span> and a continuous
outcome <span class="math inline">\(y \in \mathbb{R}\)</span>. Here,
there are <span class="math inline">\(p=400\)</span> covariates, only
<span class="math inline">\(5\)</span> of which are true signals.</p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># To reproduce:</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Random.html" class="external-link">set.seed</a></span><span class="op">(</span><span class="fl">123</span><span class="op">)</span> </span>
<span></span>
<span><span class="co"># Simulate some data:</span></span>
<span><span class="va">dat</span> <span class="op">=</span> <span class="fu"><a href="../reference/simulate_lm.html">simulate_lm</a></span><span class="op">(</span>n <span class="op">=</span> <span class="fl">200</span>,   <span class="co"># number of observations</span></span>
<span>                  p <span class="op">=</span> <span class="fl">400</span>,    <span class="co"># number of predictors</span></span>
<span>                  p_sig <span class="op">=</span> <span class="fl">5</span>, <span class="co"># number of true signals</span></span>
<span>                  SNR <span class="op">=</span> <span class="fl">1</span>    <span class="co"># signal-to-noise ratio</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Store the data:</span></span>
<span><span class="va">y</span> <span class="op">=</span> <span class="va">dat</span><span class="op">$</span><span class="va">y</span>; <span class="va">X</span> <span class="op">=</span> <span class="va">dat</span><span class="op">$</span><span class="va">X</span></span></code></pre></div>
</div>
<div class="section level2">
<h2 id="fitting-the-regression-model">Fitting the regression model<a class="anchor" aria-label="anchor" href="#fitting-the-regression-model"></a>
</h2>
<p>The first step is to fit a Bayesian regression model. Here, we will
use a linear model with horseshoe priors:</p>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/JingyuHe/bayeslm" class="external-link">bayeslm</a></span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Fit the Bayesian regression model:</span></span>
<span><span class="va">fit</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/pkg/bayeslm/man/bayeslm.html" class="external-link">bayeslm</a></span><span class="op">(</span><span class="va">y</span> <span class="op">~</span> <span class="va">X</span><span class="op">[</span>,<span class="op">-</span><span class="fl">1</span><span class="op">]</span>, <span class="co"># intercept already included</span></span>
<span>              prior <span class="op">=</span> <span class="st">'horseshoe'</span>, <span class="co"># prior on regression coefficients</span></span>
<span>              N <span class="op">=</span> <span class="fl">10000</span>, <span class="co"># MCMC samples to save</span></span>
<span>              burnin <span class="op">=</span> <span class="fl">5000</span>, <span class="co"># initial samples to discard</span></span>
<span>              singular <span class="op">=</span> <span class="cn">TRUE</span> <span class="co"># necessary for p &gt; n</span></span>
<span><span class="op">)</span></span>
<span><span class="co">#&gt; horseshoe prior </span></span>
<span><span class="co">#&gt; fixed running time 2.01974</span></span>
<span><span class="co">#&gt; sampling time 19.7884</span></span></code></pre></div>
</div>
<div class="section level2">
<h2 id="computing-optimal-linear-coefficients">Computing optimal linear coefficients<a class="anchor" aria-label="anchor" href="#computing-optimal-linear-coefficients"></a>
</h2>
<p>Given any Bayesian regression model <span class="math inline">\(M\)</span> and any subset of covariates <span class="math inline">\(S\)</span>, we compute the <strong>optimal linear
coefficients</strong> according to Bayesian decision analysis. <a href="https://doi.org/10.1080/01621459.2021.1891926" class="external-link">Kowal (2021)</a>
showed that this is obtained simply by projecting the fitted values
<span class="math inline">\(\hat y\)</span> from <span class="math inline">\(M\)</span> onto <span class="math inline">\(X_S\)</span>, i.e., the covariate matrix <span class="math inline">\(X\)</span> restricted to the columns selected in
<span class="math inline">\(S\)</span>. For an example subset <span class="math inline">\(S = \{1,3,10\}\)</span> and squared error loss,
the following code computes our optimal linear summary:</p>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Example subset:</span></span>
<span><span class="va">S_ex</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">3</span>, <span class="fl">10</span><span class="op">)</span> </span>
<span></span>
<span><span class="co"># Optimal coefficients:</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/coef.html" class="external-link">coef</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/lm.html" class="external-link">lm</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/fitted.values.html" class="external-link">fitted</a></span><span class="op">(</span><span class="va">fit</span><span class="op">)</span> <span class="op">~</span> <span class="va">X</span><span class="op">[</span>,<span class="va">S_ex</span><span class="op">]</span> <span class="op">-</span> <span class="fl">1</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt;  X[, S_ex]X1  X[, S_ex]X3 X[, S_ex]X10 </span></span>
<span><span class="co">#&gt;   -0.6296313    1.0597193   -0.2288200</span></span></code></pre></div>
</div>
<div class="section level2">
<h2 id="uncertainty-quantification-for-the-linear-coefficients">Uncertainty quantification for the linear coefficients<a class="anchor" aria-label="anchor" href="#uncertainty-quantification-for-the-linear-coefficients"></a>
</h2>
<p>We may also obtain posterior uncertainty quantification for the
linear coefficients that are active (nonzero) in <span class="math inline">\(S\)</span>. To do so, we project the posterior
predictive distribution onto <span class="math inline">\(X_S\)</span>
draw-by-draw, which induces a posterior predictive distribution for the
linear coefficients under the model <span class="math inline">\(M\)</span>—even though <span class="math inline">\(M\)</span> need not be linear in general.</p>
<p>These predictive draws are not automatically output by
<code>bayeslm</code>, so we run the following code to sample them. We
also compute the log-predictive densities which will later be used in
predictive cross-validation.</p>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Extract the posterior predictive draws and lpd:</span></span>
<span><span class="va">temp</span> <span class="op">=</span> <span class="fu"><a href="../reference/post_predict.html">post_predict</a></span><span class="op">(</span>post_y_hat <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/crossprod.html" class="external-link">tcrossprod</a></span><span class="op">(</span><span class="va">fit</span><span class="op">$</span><span class="va">beta</span>, <span class="va">X</span><span class="op">)</span>,</span>
<span>                    post_sigma <span class="op">=</span> <span class="va">fit</span><span class="op">$</span><span class="va">sigma</span>,</span>
<span>                    yy <span class="op">=</span> <span class="va">y</span><span class="op">)</span></span>
<span><span class="va">post_y_pred</span> <span class="op">=</span> <span class="va">temp</span><span class="op">$</span><span class="va">post_y_pred</span></span>
<span><span class="va">post_lpd</span> <span class="op">=</span> <span class="va">temp</span><span class="op">$</span><span class="va">post_lpd</span></span></code></pre></div>
<p>Now, we can obtain posterior predictive samples of the linear
coefficients in <span class="math inline">\(S\)</span>, and summarize
those posteriors using 95% credible intervals.</p>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Posterior predictive draws of *all* coefficients:</span></span>
<span><span class="va">post_beta_s</span> <span class="op">=</span> <span class="fu"><a href="../reference/proj_posterior.html">proj_posterior</a></span><span class="op">(</span>post_y_pred <span class="op">=</span> <span class="va">post_y_pred</span>,</span>
<span>                                 XX <span class="op">=</span> <span class="va">X</span>,</span>
<span>                                 sub_x <span class="op">=</span> <span class="va">S_ex</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/dim.html" class="external-link">dim</a></span><span class="op">(</span><span class="va">post_beta_s</span><span class="op">)</span> <span class="co"># the coefficients outside S_ex are fixed at zero</span></span>
<span><span class="co">#&gt; [1] 10000   401</span></span>
<span></span>
<span><span class="co"># Compute 95% credible intervals for the nonzero entries:</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/t.html" class="external-link">t</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/apply.html" class="external-link">apply</a></span><span class="op">(</span><span class="va">post_beta_s</span><span class="op">[</span>,<span class="va">S_ex</span><span class="op">]</span>, <span class="fl">2</span>, </span>
<span>        <span class="va">quantile</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">0.05</span><span class="op">/</span><span class="fl">2</span>, <span class="fl">1</span> <span class="op">-</span> <span class="fl">0.05</span><span class="op">/</span><span class="fl">2</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt;           2.5%      97.5%</span></span>
<span><span class="co">#&gt; X1  -1.1040525 -0.1544037</span></span>
<span><span class="co">#&gt; X3   0.5828605  1.5262942</span></span>
<span><span class="co">#&gt; X10 -0.6296572  0.1535756</span></span></code></pre></div>
</div>
<div class="section level2">
<h2 id="bayesian-subset-search">Bayesian subset search<a class="anchor" aria-label="anchor" href="#bayesian-subset-search"></a>
</h2>
<p>To this point, we have focused on point and interval (linear)
summaries for an arbitrary yet fixed subset <span class="math inline">\(S\)</span>. However, we are often interested in
<em>searching</em> across subsets and measuring the predictive
performances. Here, we use the model <span class="math inline">\(M\)</span> output to generate a collection of
“candidate subsets” using decision analysis <a href="https://jmlr.org/papers/v23/21-0403.html" class="external-link">(Kowal, 2022a)</a>.</p>
<p>To make the search feasible for large <span class="math inline">\(p\)</span>, we first <em>pre-screen</em> to <span class="math inline">\(k \ll p\)</span> covariates. We do this using the
posterior draws of <span class="math inline">\(\beta\)</span> under
<span class="math inline">\(M\)</span>, but variations are available
when <span class="math inline">\(M\)</span> is nonlinear. Specifically,
we retain the top <span class="math inline">\(k\)</span> covariates by
effect size.</p>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Allowable covariates:</span></span>
<span><span class="va">to_consider</span> <span class="op">=</span> <span class="fu"><a href="../reference/prescreen.html">prescreen</a></span><span class="op">(</span><span class="va">fit</span><span class="op">$</span><span class="va">beta</span>, num_to_keep <span class="op">=</span> <span class="fl">30</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Exclude the rest:</span></span>
<span><span class="va">to_exclude</span> <span class="op">=</span> <span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html" class="external-link">ncol</a></span><span class="op">(</span><span class="va">X</span><span class="op">)</span><span class="op">)</span><span class="op">[</span><span class="op">-</span><span class="va">to_consider</span><span class="op">]</span></span></code></pre></div>
<p>Only these <span class="math inline">\(k\)</span> covariates are
permitted to be active. This makes the branch-and-bound algorithm
feasible. Then, as in our other vignettes, we screen to the “best”
<code>n_best = 50</code> models of each size according to squared error
loss. We store these in a Boolean matrix <code>indicators</code>: each
row is an individual subset, while the columns indicate which variables
are included (<code>TRUE</code>) or excluded (<code>FALSE</code>).</p>
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">indicators</span> <span class="op">=</span> <span class="fu"><a href="../reference/branch_and_bound.html">branch_and_bound</a></span><span class="op">(</span>yy <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/fitted.values.html" class="external-link">fitted</a></span><span class="op">(</span><span class="va">fit</span><span class="op">)</span>, <span class="co"># response is the fitted values</span></span>
<span>                             XX <span class="op">=</span> <span class="va">X</span>,            <span class="co"># covariates</span></span>
<span>                             n_best <span class="op">=</span> <span class="fl">50</span>,       <span class="co"># restrict to the "best" 15 subsets of each size</span></span>
<span>                             to_include <span class="op">=</span> <span class="fl">1</span>,    <span class="co"># keep the intercept always</span></span>
<span>                             to_exclude <span class="op">=</span> <span class="va">to_exclude</span> <span class="co"># pre-screened</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Inspect:</span></span>
<span><span class="va">indicators</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fl">5</span>, <span class="fl">1</span><span class="op">:</span><span class="fl">10</span><span class="op">]</span></span>
<span><span class="co">#&gt;            X1    X2    X3    X4    X5    X6    X7    X8    X9   X10</span></span>
<span><span class="co">#&gt; force_in TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE</span></span>
<span><span class="co">#&gt;          TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE</span></span>
<span><span class="co">#&gt;          TRUE FALSE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE</span></span>
<span><span class="co">#&gt;          TRUE FALSE FALSE FALSE FALSE  TRUE FALSE FALSE FALSE FALSE</span></span>
<span><span class="co">#&gt;          TRUE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE</span></span>
<span></span>
<span><span class="co"># Dimensions:</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/dim.html" class="external-link">dim</a></span><span class="op">(</span><span class="va">indicators</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] 1360  401</span></span>
<span></span>
<span><span class="co"># Summarize the model sizes:</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/table.html" class="external-link">table</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/colSums.html" class="external-link">rowSums</a></span><span class="op">(</span><span class="va">indicators</span><span class="op">)</span><span class="op">)</span> <span class="co"># note: intercept always included</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 </span></span>
<span><span class="co">#&gt;  1 29 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 </span></span>
<span><span class="co">#&gt; 27 28 29 30 </span></span>
<span><span class="co">#&gt; 50 50 29  1</span></span></code></pre></div>
</div>
<div class="section level2">
<h2 id="the-acceptable-family-of-near-optimal-subsets">The acceptable family of “near-optimal” subsets<a class="anchor" aria-label="anchor" href="#the-acceptable-family-of-near-optimal-subsets"></a>
</h2>
<p>From this large collection of 1360 candidate subsets, we seek to
filter to the <strong>acceptable family</strong> of subsets, i.e., those
“near-optimal” subsets that predict about as well as the “best” subset.
These are computed based on 10-fold cross-validation, and use the
out-of-sample predictive distribution from <span class="math inline">\(M\)</span> to provide uncertainty quantification
for predictive accuracy.</p>
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Compute the acceptable family:</span></span>
<span><span class="va">accept_info</span> <span class="op">=</span> <span class="fu"><a href="../reference/accept_family.html">accept_family</a></span><span class="op">(</span>post_y_pred <span class="op">=</span> <span class="va">post_y_pred</span>,</span>
<span>                            post_lpd <span class="op">=</span> <span class="va">post_lpd</span>,</span>
<span>                            XX <span class="op">=</span> <span class="va">X</span>,</span>
<span>                            indicators <span class="op">=</span> <span class="va">indicators</span>,</span>
<span>                            yy <span class="op">=</span> <span class="va">y</span>,</span>
<span>                            post_y_hat <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/crossprod.html" class="external-link">tcrossprod</a></span><span class="op">(</span><span class="va">fit</span><span class="op">$</span><span class="va">beta</span>, <span class="va">X</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<p><img src="High-dim_files/figure-html/accept-1.png" width="576"></p>
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span></span>
<span><span class="co"># How many subsets are in the acceptable family?</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/length.html" class="external-link">length</a></span><span class="op">(</span><span class="va">accept_info</span><span class="op">$</span><span class="va">all_accept</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] 1178</span></span>
<span></span>
<span><span class="co"># These are the rows of `indicators` that belong to the acceptable family:</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/head.html" class="external-link">head</a></span><span class="op">(</span><span class="va">accept_info</span><span class="op">$</span><span class="va">all_accept</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] 131 132 181 182 183 184</span></span>
<span></span>
<span><span class="co"># An example acceptable subset:</span></span>
<span><span class="va">ex_accept</span> <span class="op">=</span> <span class="va">accept_info</span><span class="op">$</span><span class="va">all_accept</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/which.html" class="external-link">which</a></span><span class="op">(</span><span class="va">indicators</span><span class="op">[</span><span class="va">ex_accept</span>,<span class="op">]</span><span class="op">)</span></span>
<span><span class="co">#&gt;   X1   X3   X4   X6 X173 </span></span>
<span><span class="co">#&gt;    1    3    4    6  173</span></span></code></pre></div>
<p>The plot shows how the out-of-sample predictive performance varies
across subsets of different sizes, specifically relative (% change) to
the “best” subset (by minimum cross-validated error; dashed gray
vertical line). The x-marks are the (usual) empirical cross-validated
error, while the intervals leverage the predictive distribution from
<span class="math inline">\(M\)</span> to quantify uncertainty in the
out-of-sample predictive performance. While performance improves as
variables are added, it is clear that several smaller subsets are highly
competitive—especially when accounting for the predictive
uncertainty.</p>
</div>
<div class="section level2">
<h2 id="subset-selection-the-smallest-acceptable-subset">Subset selection: the smallest acceptable subset<a class="anchor" aria-label="anchor" href="#subset-selection-the-smallest-acceptable-subset"></a>
</h2>
<p>If we wish to <strong>select</strong> a single subset, a compelling
representative of the acceptable family is the <strong>smallest</strong>
acceptable subset. This choice favors parsimony, while its membership in
the acceptable family implies that it meets a high standard for
predictive accuracy. From the previous plot, we select the smallest
subset for which the intervals include zero (solid gray vertical
line).</p>
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Simplest acceptable subset:</span></span>
<span><span class="va">beta_hat_small</span> <span class="op">=</span> <span class="va">accept_info</span><span class="op">$</span><span class="va">beta_hat_small</span></span>
<span></span>
<span><span class="co"># Which coefficients are nonzero:</span></span>
<span><span class="va">S_small</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/which.html" class="external-link">which</a></span><span class="op">(</span><span class="va">beta_hat_small</span> <span class="op">!=</span> <span class="fl">0</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># How many coefficients are nonzero:</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/length.html" class="external-link">length</a></span><span class="op">(</span><span class="va">S_small</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] 5</span></span></code></pre></div>
<p>The “best” subset by minimum cross-validation often includes many
extraneous variables, which is a well-known (and undesirable) byproduct
of cross-validation.</p>
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Acceptable subset that minimizes CV error:</span></span>
<span><span class="va">beta_hat_min</span> <span class="op">=</span> <span class="va">accept_info</span><span class="op">$</span><span class="va">beta_hat_min</span></span>
<span></span>
<span><span class="co"># Typically much larger (and often too large...)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/sum.html" class="external-link">sum</a></span><span class="op">(</span><span class="va">beta_hat_min</span> <span class="op">!=</span> <span class="fl">0</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] 27</span></span></code></pre></div>
<p>For reference, the true model size is 6. Clearly, the “best” subset
is unsatisfactory.</p>
<p>Returning to the <em>smallest</em> acceptable subset, we can obtain
posterior samples and credible intervals for the coefficients as
before:</p>
<div class="sourceCode" id="cb13"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Draws from the posterior predictive distribution</span></span>
<span><span class="va">post_beta_small</span> <span class="op">=</span> <span class="fu"><a href="../reference/proj_posterior.html">proj_posterior</a></span><span class="op">(</span>post_y_pred <span class="op">=</span> <span class="va">post_y_pred</span>,</span>
<span>                                 XX <span class="op">=</span> <span class="va">X</span>,</span>
<span>                                 sub_x <span class="op">=</span> <span class="va">S_small</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Compute 95% credible intervals for the nonzero entries:</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/t.html" class="external-link">t</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/apply.html" class="external-link">apply</a></span><span class="op">(</span><span class="va">post_beta_small</span><span class="op">[</span>,<span class="va">S_small</span><span class="op">]</span>, <span class="fl">2</span>, </span>
<span>        <span class="va">quantile</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">0.05</span><span class="op">/</span><span class="fl">2</span>, <span class="fl">1</span> <span class="op">-</span> <span class="fl">0.05</span><span class="op">/</span><span class="fl">2</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt;            2.5%      97.5%</span></span>
<span><span class="co">#&gt; X1   -1.3650754 -0.3892930</span></span>
<span><span class="co">#&gt; X3    0.5819645  1.5333044</span></span>
<span><span class="co">#&gt; X4    0.7520160  1.7982194</span></span>
<span><span class="co">#&gt; X6   -1.6517656 -0.7025616</span></span>
<span><span class="co">#&gt; X173 -1.4220912 -0.4092995</span></span></code></pre></div>
</div>
<div class="section level2">
<h2 id="variable-importance-from-acceptable-subsets">Variable importance from acceptable subsets<a class="anchor" aria-label="anchor" href="#variable-importance-from-acceptable-subsets"></a>
</h2>
<p>The <strong>variable importance</strong> which reports, for each
variable <span class="math inline">\(j\)</span>, the proportion of
acceptable subsets in which <span class="math inline">\(j\)</span>
appears. However, we must interpret this with additional caution: the
pre-screening procedure eliminates certain variables from consideration
for the acceptable family, and thus each of these variables will be
assigned an importance value of zero. As a result, it is more
informative to focus on the variables that appear in <em>some</em> or
<em>all</em> acceptable subsets.</p>
<div class="sourceCode" id="cb14"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Variable importance: proportion of *acceptable subsets* in which each variable appears</span></span>
<span><span class="va">vi_e</span> <span class="op">=</span> <span class="fu"><a href="../reference/var_imp.html">var_imp</a></span><span class="op">(</span>indicators <span class="op">=</span> <span class="va">indicators</span>,</span>
<span>               all_accept <span class="op">=</span> <span class="va">accept_info</span><span class="op">$</span><span class="va">all_accept</span><span class="op">)</span><span class="op">$</span><span class="va">vi_inc</span></span>
<span></span>
<span><span class="co"># "Keystone covariates" that appear in *all* acceptable families:</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/which.html" class="external-link">which</a></span><span class="op">(</span><span class="va">vi_e</span> <span class="op">==</span> <span class="fl">1</span><span class="op">)</span></span>
<span><span class="co">#&gt; 1 3 4 6 </span></span>
<span><span class="co">#&gt; 1 3 4 6</span></span>
<span></span>
<span><span class="co"># Visualize:</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/barplot.html" class="external-link">barplot</a></span><span class="op">(</span><span class="va">vi_e</span><span class="op">[</span><span class="fu"><a href="https://rdrr.io/r/base/order.html" class="external-link">order</a></span><span class="op">(</span><span class="va">vi_e</span>, <span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html" class="external-link">ncol</a></span><span class="op">(</span><span class="va">X</span><span class="op">)</span><span class="op">:</span><span class="fl">1</span><span class="op">)</span><span class="op">)</span><span class="op">]</span>, <span class="co"># order...</span></span>
<span>        horiz <span class="op">=</span> <span class="cn">TRUE</span>, </span>
<span>        main <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/paste.html" class="external-link">paste</a></span><span class="op">(</span><span class="st">'Variable importance for the acceptable family'</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/abline.html" class="external-link">abline</a></span><span class="op">(</span>v <span class="op">=</span> <span class="fl">1</span><span class="op">)</span></span></code></pre></div>
<p><img src="High-dim_files/figure-html/vi-1.png" width="576"></p>
<p>As expected, most variables (specifically, 371) end up with a value
of exactly zero, due to the pre-screening procedure. However, among the
candidate variables, there is still some variability in the variable
importances, which is quantified by the summary output:</p>
<div class="sourceCode" id="cb15"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Summary stats for the nonzero VIs:</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html" class="external-link">summary</a></span><span class="op">(</span><span class="va">vi_e</span><span class="op">[</span><span class="va">vi_e</span> <span class="op">!=</span> <span class="fl">0</span><span class="op">]</span><span class="op">)</span></span>
<span><span class="co">#&gt;    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. </span></span>
<span><span class="co">#&gt;  0.1036  0.2924  0.5577  0.5755  0.8686  1.0000</span></span></code></pre></div>
</div>
  </main><aside class="col-md-3"><nav id="toc"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p></p>
<p>Developed by Dan Kowal.</p>
</div>

<div class="pkgdown-footer-right">
  <p></p>
<p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.0.7.</p>
</div>

    </footer>
</div>

  

  

  </body>
</html>
