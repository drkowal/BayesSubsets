<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="description" content='Given any Bayesian model for prediction or classification,
    these tools will (i) search for the "best" subsets of linear predictors;
    (ii) collect the *acceptable family* of near-optimal subsets of linear predictors
    that match or nearly-match the predictive performance of the "best" model (according to 
    predictive cross-validation); (iii) summarize the acceptable family using the "best" model,
    the smallest acceptable model, and customized variable importance metrics; and (iv) provide
    predictive uncertainty quantification for the linear coefficients. In effect, these methods
    provide interpretable (linear) summaries of the Bayesian model. The strategy of collecting 
    the acceptable family of subsets substantially reduces the inherent sensitivity in selecting 
    a single "best" model and recognizes that many different subsets may perform quite well. 
    For any subset of covariates, the estimated linear coefficients are optimal in a Bayesian 
    decision analysis sense. Details of the methods and algorithms are 
    provided in Kowal (2023) &lt;https://jmlr.org/papers/v23/21-0403.html&gt;.'>
<title>Bayesian Subset Selection and Variable Importance • BayesSubsets</title>
<script src="deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="deps/bootstrap-5.2.2/bootstrap.min.css" rel="stylesheet">
<script src="deps/bootstrap-5.2.2/bootstrap.bundle.min.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- bootstrap-toc --><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@v1.0.1/dist/bootstrap-toc.min.js" integrity="sha256-4veVQbu7//Lk5TSmc7YV48MxtMy98e26cf5MrgZYnwo=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- search --><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- pkgdown --><script src="pkgdown.js"></script><meta property="og:title" content="Bayesian Subset Selection and Variable Importance">
<meta property="og:description" content='Given any Bayesian model for prediction or classification,
    these tools will (i) search for the "best" subsets of linear predictors;
    (ii) collect the *acceptable family* of near-optimal subsets of linear predictors
    that match or nearly-match the predictive performance of the "best" model (according to 
    predictive cross-validation); (iii) summarize the acceptable family using the "best" model,
    the smallest acceptable model, and customized variable importance metrics; and (iv) provide
    predictive uncertainty quantification for the linear coefficients. In effect, these methods
    provide interpretable (linear) summaries of the Bayesian model. The strategy of collecting 
    the acceptable family of subsets substantially reduces the inherent sensitivity in selecting 
    a single "best" model and recognizes that many different subsets may perform quite well. 
    For any subset of covariates, the estimated linear coefficients are optimal in a Bayesian 
    decision analysis sense. Details of the methods and algorithms are 
    provided in Kowal (2023) &lt;https://jmlr.org/papers/v23/21-0403.html&gt;.'>
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>
    

    <nav class="navbar fixed-top navbar-light navbar-expand-lg bg-light"><div class="container">
    
    <a class="navbar-brand me-2" href="index.html">BayesSubsets</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">0.1.0</small>

    
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item">
  <a class="nav-link" href="articles/BayesSubsets.html">Get started</a>
</li>
<li class="nav-item">
  <a class="nav-link" href="reference/index.html">Reference</a>
</li>
<li class="nav-item dropdown">
  <a href="#" class="nav-link dropdown-toggle" data-bs-toggle="dropdown" role="button" aria-expanded="false" aria-haspopup="true" id="dropdown-articles">Articles</a>
  <div class="dropdown-menu" aria-labelledby="dropdown-articles">
    <a class="dropdown-item" href="articles/Binary-target.html">Targeted Prediction and Binary Outcomes</a>
    <a class="dropdown-item" href="articles/High-dim.html">BayesSubsets with high-dimensional data</a>
    <a class="dropdown-item" href="articles/Linear-mixed.html">Bayesian subset selection for linear mixed models</a>
  </div>
</li>
      </ul>
<form class="form-inline my-2 my-lg-0" role="search">
        <input type="search" class="form-control me-sm-2" aria-label="Toggle navigation" name="search-input" data-search-index="search.json" id="search-input" placeholder="Search for" autocomplete="off">
</form>

      <ul class="navbar-nav">
<li class="nav-item">
  <a class="external-link nav-link" href="https://github.com/drkowal/BayesSubsets/" aria-label="github">
    <span class="fab fa fab fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
</div>

    
  </div>
</nav><div class="container template-home">
<div class="row">
  <main id="main" class="col-md-9"><div class="section level1">
<div class="page-header"><h1 id="bayessubsets">BayesSubsets<a class="anchor" aria-label="anchor" href="#bayessubsets"></a>
</h1></div>
<!-- badges: start -->
<!-- badges: end -->
<p><code>BayesSubsets</code> provides <strong>Bayesian subset selection</strong> for a variety of Bayesian regression models. These include:</p>
<ul>
<li><p>Bayesian regression of <span class="math inline"><em>y</em> ∈ ℝ</span> or <span class="math inline"><em>y</em> ∈ {0, 1}</span> on (<span class="math inline"><em>n</em> × <em>p</em></span>) covariates <span class="math inline"><em>X</em></span> <a href="https://jmlr.org/papers/v23/21-0403.html" class="external-link">(Kowal, 2022a)</a></p></li>
<li><p>Targeted prediction for <span class="math inline"><em>h</em>(<em>ỹ</em>)</span>, where <span class="math inline"><em>h</em></span> is a known functional that describes a key outcome of interest (e.g., <span class="math inline"><em>y</em></span> is continuous, and <span class="math inline"><em>h</em></span> is an indicator for exceedance of a threshold); multiple functionals can be considered for a single model <a href="https://doi.org/10.1080/01621459.2021.1891926" class="external-link">(Kowal, 2021)</a></p></li>
<li><p>Bayesian linear mixed models that regress <span class="math inline"><em>Y</em></span> (<span class="math inline"><em>m</em> × <em>n</em></span>) on <span class="math inline"><em>X</em></span>, where we observe <span class="math inline"><em>m</em></span> repeated measurements for each subject <span class="math inline"><em>i</em> = 1, …, <em>n</em></span> <a href="https://doi.org/10.1111/biom.13707" class="external-link">(Kowal, 2022b)</a>.</p></li>
</ul>
<p>These specific cases are explored in the vignettes.</p>
<p>For <em>any</em> Bayesian regression model <span class="math inline"><em>M</em></span>, <code>BayesSubsets</code> provides:</p>
<ol style="list-style-type: decimal">
<li><p>Optimal <strong>linear</strong> coefficients (with uncertainty quantification) for a <em>given</em> subset of covariates;</p></li>
<li><p>The <strong>acceptable family</strong> of subsets that are <em>near-optimal</em> linear predictors relative to the “best” subset (according to cross-validation);</p></li>
<li><p>The <strong>smallest acceptable subset</strong>, which prioritizes parsimony while maintaining predictive accuracy; and</p></li>
<li><p>The <strong>variable importance</strong> for the acceptable family, which provides variable-specific summaries of these near-optimal subsets.</p></li>
</ol>
<p>The smallest acceptable subset is a reasonable default choice for subset selection. However, we caution against the overreliance on any single subset without compelling motivation. A key contribution of the acceptable family is that it identifies <em>many</em> competing explanations (subsets) that are nearly indistinguishable in predictive accuracy. From a purely predictive perspective, we cannot completely rule out any member of the acceptable family. As such, we recommend including the <em>variable importance</em> metric to summarize the many near-optimal linear predictors.</p>
<div class="section level2">
<h2 id="installation">Installation<a class="anchor" aria-label="anchor" href="#installation"></a>
</h2>
<p>You can install the development version of <code>BayesSubsets</code> from <a href="https://github.com/" class="external-link">GitHub</a> with:</p>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># install.packages("devtools")</span></span>
<span><span class="fu">devtools</span><span class="fu">::</span><span class="fu">install_github</span><span class="op">(</span><span class="st">"drkowal/BayesSubsets"</span><span class="op">)</span></span></code></pre></div>
</div>
<div class="section level2">
<h2 id="example-use">Example use<a class="anchor" aria-label="anchor" href="#example-use"></a>
</h2>
<p>To illustrate the use of <code>BayesSubsets</code>, we present an example with simulated data and a Bayesian linear model. The vignettes explore this and other cases in more detail.</p>
<p>First, load the package:</p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/drkowal/BayesSubsets" class="external-link">BayesSubsets</a></span><span class="op">)</span></span></code></pre></div>
<p>Then simulate data:</p>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># To reproduce:</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Random.html" class="external-link">set.seed</a></span><span class="op">(</span><span class="fl">123</span><span class="op">)</span> </span>
<span></span>
<span><span class="co"># Simulate some data:</span></span>
<span><span class="va">dat</span> <span class="op">=</span> <span class="fu"><a href="reference/simulate_lm.html">simulate_lm</a></span><span class="op">(</span>n <span class="op">=</span> <span class="fl">200</span>,   <span class="co"># number of observations</span></span>
<span>                  p <span class="op">=</span> <span class="fl">10</span>,    <span class="co"># number of predictors</span></span>
<span>                  p_sig <span class="op">=</span> <span class="fl">5</span>, <span class="co"># number of true signals</span></span>
<span>                  SNR <span class="op">=</span> <span class="fl">1</span>    <span class="co"># signal-to-noise ratio</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Store the data:</span></span>
<span><span class="va">y</span> <span class="op">=</span> <span class="va">dat</span><span class="op">$</span><span class="va">y</span>; <span class="va">X</span> <span class="op">=</span> <span class="va">dat</span><span class="op">$</span><span class="va">X</span></span></code></pre></div>
<p>Next, we fit a Bayesian linear model. The output from <code>bayeslm</code> does not include posterior predictive draws or log-predictive density evaluations, so we compute those as well.</p>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Package for efficient Bayesian linear regression:</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/JingyuHe/bayeslm" class="external-link">bayeslm</a></span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Fit the Bayesian regression model:</span></span>
<span><span class="va">fit</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/pkg/bayeslm/man/bayeslm.html" class="external-link">bayeslm</a></span><span class="op">(</span><span class="va">y</span> <span class="op">~</span> <span class="va">X</span><span class="op">[</span>,<span class="op">-</span><span class="fl">1</span><span class="op">]</span>, <span class="co"># intercept already included</span></span>
<span>              N <span class="op">=</span> <span class="fl">10000</span>, <span class="co"># MCMC samples to save</span></span>
<span>              burnin <span class="op">=</span> <span class="fl">5000</span> <span class="co"># initial samples to discard</span></span>
<span><span class="op">)</span></span>
<span><span class="co">#&gt; horseshoe prior </span></span>
<span><span class="co">#&gt; fixed running time 0.000730958</span></span>
<span><span class="co">#&gt; sampling time 0.104625</span></span>
<span></span>
<span><span class="co"># Extract the posterior predictive draws and lpd:</span></span>
<span><span class="va">temp</span> <span class="op">=</span> <span class="fu"><a href="reference/post_predict.html">post_predict</a></span><span class="op">(</span>post_y_hat <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/crossprod.html" class="external-link">tcrossprod</a></span><span class="op">(</span><span class="va">fit</span><span class="op">$</span><span class="va">beta</span>, <span class="va">X</span><span class="op">)</span>,</span>
<span>                    post_sigma <span class="op">=</span> <span class="va">fit</span><span class="op">$</span><span class="va">sigma</span>,</span>
<span>                    yy <span class="op">=</span> <span class="va">y</span><span class="op">)</span></span>
<span><span class="va">post_y_pred</span> <span class="op">=</span> <span class="va">temp</span><span class="op">$</span><span class="va">post_y_pred</span></span>
<span><span class="va">post_lpd</span> <span class="op">=</span> <span class="va">temp</span><span class="op">$</span><span class="va">post_lpd</span></span></code></pre></div>
<p>Using the model output, we enumerate a collection of “candidate subsets”. For small <span class="math inline"><em>p</em></span> it may be possible to include all possible subsets. Here, we screen to the “best” <code>n_best = 50</code> models of each size according to squared error loss. We store these in a Boolean matrix <code>indicators</code>: each row is an individual subset, while the columns indicate which variables are included (<code>TRUE</code>) or excluded (<code>FALSE</code>).</p>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">indicators</span> <span class="op">=</span> <span class="fu"><a href="reference/branch_and_bound.html">branch_and_bound</a></span><span class="op">(</span>yy <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/fitted.values.html" class="external-link">fitted</a></span><span class="op">(</span><span class="va">fit</span><span class="op">)</span>, <span class="co"># response is the fitted values</span></span>
<span>                             XX <span class="op">=</span> <span class="va">X</span>,            <span class="co"># covariates</span></span>
<span>                             n_best <span class="op">=</span> <span class="fl">50</span>        <span class="co"># restrict to the "best" 50 subsets of each size</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Inspect:</span></span>
<span><span class="va">indicators</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fl">5</span>, <span class="fl">1</span><span class="op">:</span><span class="fl">10</span><span class="op">]</span></span>
<span><span class="co">#&gt;            X1    X2    X3    X4    X5    X6    X7    X8    X9   X10</span></span>
<span><span class="co">#&gt; force_in TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE</span></span>
<span><span class="co">#&gt;          TRUE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE</span></span>
<span><span class="co">#&gt;          TRUE FALSE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE</span></span>
<span><span class="co">#&gt;          TRUE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE</span></span>
<span><span class="co">#&gt;          TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE  TRUE FALSE</span></span>
<span></span>
<span><span class="co"># Dimensions:</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/dim.html" class="external-link">dim</a></span><span class="op">(</span><span class="va">indicators</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] 362  11</span></span>
<span></span>
<span><span class="co"># Summarize the model sizes:</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/table.html" class="external-link">table</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/colSums.html" class="external-link">rowSums</a></span><span class="op">(</span><span class="va">indicators</span><span class="op">)</span><span class="op">)</span> <span class="co"># note: intercept always included</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;  1  2  3  4  5  6  7  8  9 10 11 </span></span>
<span><span class="co">#&gt;  1 10 45 50 50 50 50 50 45 10  1</span></span></code></pre></div>
<p>From this collection of 362 candidate subsets, we seek to filter to the <strong>acceptable family</strong> of subsets, i.e., those “near-optimal” subsets that predict about as well as the “best” subset. These are computed based on 10-fold cross-validation, and use the out-of-sample predictive distribution from <span class="math inline"><em>M</em></span> to provide uncertainty quantification for predictive accuracy.</p>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Compute the acceptable family:</span></span>
<span><span class="va">accept_info</span> <span class="op">=</span> <span class="fu"><a href="reference/accept_family.html">accept_family</a></span><span class="op">(</span>post_y_pred <span class="op">=</span> <span class="va">post_y_pred</span>,</span>
<span>                            post_lpd <span class="op">=</span> <span class="va">post_lpd</span>,</span>
<span>                            XX <span class="op">=</span> <span class="va">X</span>,</span>
<span>                            indicators <span class="op">=</span> <span class="va">indicators</span>,</span>
<span>                            yy <span class="op">=</span> <span class="va">y</span>,</span>
<span>                            post_y_hat <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/crossprod.html" class="external-link">tcrossprod</a></span><span class="op">(</span><span class="va">fit</span><span class="op">$</span><span class="va">beta</span>, <span class="va">X</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<p><img src="reference/figures/README-accept-1.png" width="100%"></p>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span></span>
<span><span class="co"># How many subsets are in the acceptable family?</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/length.html" class="external-link">length</a></span><span class="op">(</span><span class="va">accept_info</span><span class="op">$</span><span class="va">all_accept</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] 103</span></span>
<span></span>
<span><span class="co"># These are the rows of `indicators` that belong to the acceptable family:</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/head.html" class="external-link">head</a></span><span class="op">(</span><span class="va">accept_info</span><span class="op">$</span><span class="va">all_accept</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] 107 157 158 159 160 161</span></span>
<span></span>
<span><span class="co"># An example acceptable subset:</span></span>
<span><span class="va">ex_accept</span> <span class="op">=</span> <span class="va">accept_info</span><span class="op">$</span><span class="va">all_accept</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/which.html" class="external-link">which</a></span><span class="op">(</span><span class="va">indicators</span><span class="op">[</span><span class="va">ex_accept</span>,<span class="op">]</span><span class="op">)</span></span>
<span><span class="co">#&gt; X1 X3 X4 X5 X6 </span></span>
<span><span class="co">#&gt;  1  3  4  5  6</span></span></code></pre></div>
<p>The plot shows how the out-of-sample predictive performance varies across subsets of different sizes, specifically relative (% change) to the “best” subset (by minimum cross-validated error; dashed gray vertical line). The x-marks are the (usual) empirical cross-validated error, while the intervals leverage the predictive distribution from <span class="math inline"><em>M</em></span> to quantify uncertainty in the out-of-sample predictive performance. While performance improves as variables are added, it is clear that several smaller subsets are highly competitive—especially when accounting for the predictive uncertainty.</p>
<p>If we wish to <strong>select</strong> a single subset, a compelling representative of the acceptable family is the <strong>smallest</strong> acceptable subset. This choice favors parsimony, while its membership in the acceptable family implies that it meets a high standard for predictive accuracy. From the previous plot, we select the smallest subset for which the intervals include zero (solid gray vertical line).</p>
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Simplest acceptable subset:</span></span>
<span><span class="va">beta_hat_small</span> <span class="op">=</span> <span class="va">accept_info</span><span class="op">$</span><span class="va">beta_hat_small</span></span>
<span></span>
<span><span class="co"># Which coefficients are nonzero:</span></span>
<span><span class="va">S_small</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/which.html" class="external-link">which</a></span><span class="op">(</span><span class="va">beta_hat_small</span> <span class="op">!=</span> <span class="fl">0</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># How many coefficients are nonzero:</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/length.html" class="external-link">length</a></span><span class="op">(</span><span class="va">S_small</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] 5</span></span></code></pre></div>
<p>The “best” subset by minimum cross-validation often includes many extraneous variables, which is a well-known (and undesirable) byproduct of cross-validation.</p>
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Acceptable subset that minimizes CV error:</span></span>
<span><span class="va">beta_hat_min</span> <span class="op">=</span> <span class="va">accept_info</span><span class="op">$</span><span class="va">beta_hat_min</span></span>
<span></span>
<span><span class="co"># Typically much larger (and often too large...)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/sum.html" class="external-link">sum</a></span><span class="op">(</span><span class="va">beta_hat_min</span> <span class="op">!=</span> <span class="fl">0</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] 8</span></span></code></pre></div>
<p>For reference, the true model size is 6.</p>
<p>Returning to the <em>smallest</em> acceptable subset, we can obtain posterior samples and credible intervals for the coefficients as before:</p>
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Draws from the posterior predictive distribution</span></span>
<span><span class="va">post_beta_small</span> <span class="op">=</span> <span class="fu"><a href="reference/proj_posterior.html">proj_posterior</a></span><span class="op">(</span>post_y_pred <span class="op">=</span> <span class="va">post_y_pred</span>,</span>
<span>                                 XX <span class="op">=</span> <span class="va">X</span>,</span>
<span>                                 sub_x <span class="op">=</span> <span class="va">S_small</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Compute 95% credible intervals for the nonzero entries:</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/t.html" class="external-link">t</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/apply.html" class="external-link">apply</a></span><span class="op">(</span><span class="va">post_beta_small</span><span class="op">[</span>,<span class="va">S_small</span><span class="op">]</span>, <span class="fl">2</span>, </span>
<span>        <span class="va">quantile</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">0.05</span><span class="op">/</span><span class="fl">2</span>, <span class="fl">1</span> <span class="op">-</span> <span class="fl">0.05</span><span class="op">/</span><span class="fl">2</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt;          2.5%      97.5%</span></span>
<span><span class="co">#&gt; X1 -1.6918273 -0.8464020</span></span>
<span><span class="co">#&gt; X3  0.6238419  1.8385971</span></span>
<span><span class="co">#&gt; X4  1.0472439  2.1673297</span></span>
<span><span class="co">#&gt; X5 -1.3055990 -0.4155887</span></span>
<span><span class="co">#&gt; X6 -1.5278812 -0.5626135</span></span></code></pre></div>
<p>Another useful summary of the acceptable family is the <strong>variable importance</strong>, which reports, for each variable <span class="math inline"><em>j</em></span>, the proportion of acceptable subsets in which <span class="math inline"><em>j</em></span> appears. We are particularly interested in distinguishing among those variables that occur in <em>all</em>, <em>some</em>, or <em>no</em> acceptable subsets, which provides insight about which variables are indispensable (“keystone covariates”) and which variables are part of a “predictively plausible” explanation.</p>
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Variable importance: proportion of *acceptable subsets* in which each variable appears</span></span>
<span><span class="va">vi_e</span> <span class="op">=</span> <span class="fu"><a href="reference/var_imp.html">var_imp</a></span><span class="op">(</span>indicators <span class="op">=</span> <span class="va">indicators</span>,</span>
<span>               all_accept <span class="op">=</span> <span class="va">accept_info</span><span class="op">$</span><span class="va">all_accept</span><span class="op">)</span><span class="op">$</span><span class="va">vi_inc</span></span>
<span></span>
<span><span class="co"># "Keystone covariates" that appear in *all* acceptable families:</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/which.html" class="external-link">which</a></span><span class="op">(</span><span class="va">vi_e</span> <span class="op">==</span> <span class="fl">1</span><span class="op">)</span></span>
<span><span class="co">#&gt; 1 4 6 </span></span>
<span><span class="co">#&gt; 1 4 6</span></span>
<span></span>
<span><span class="co"># Irrelevant covariates that appear in *no* acceptable families:</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/which.html" class="external-link">which</a></span><span class="op">(</span><span class="va">vi_e</span> <span class="op">==</span> <span class="fl">0</span><span class="op">)</span> </span>
<span><span class="co">#&gt; named integer(0)</span></span>
<span></span>
<span><span class="co"># Visualize:</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/barplot.html" class="external-link">barplot</a></span><span class="op">(</span><span class="va">vi_e</span><span class="op">[</span><span class="fu"><a href="https://rdrr.io/r/base/order.html" class="external-link">order</a></span><span class="op">(</span><span class="va">vi_e</span>, <span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html" class="external-link">ncol</a></span><span class="op">(</span><span class="va">X</span><span class="op">)</span><span class="op">:</span><span class="fl">1</span><span class="op">)</span><span class="op">)</span><span class="op">]</span>, <span class="co"># order...</span></span>
<span>        horiz <span class="op">=</span> <span class="cn">TRUE</span>, </span>
<span>        main <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/paste.html" class="external-link">paste</a></span><span class="op">(</span><span class="st">'Variable importance for the acceptable family'</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/abline.html" class="external-link">abline</a></span><span class="op">(</span>v <span class="op">=</span> <span class="fl">1</span><span class="op">)</span></span></code></pre></div>
<p><img src="reference/figures/README-vi-1.png" width="100%"></p>
<p>Each variable appears in quite a few acceptable subsets, which is unsurprising: the covariates are moderately correlated, so it is reasonable to expect that some are roughly interchangeable in terms of predictive accuracy.</p>
<p>Finally, we compare the point and interval summaries from the smallest acceptable subset to the traditional point and interval summaries from the Bayesian linear model: the posterior mean and 95% credible intervals for <span class="math inline"><em>β</em></span>.</p>
<p><img src="reference/figures/README-plot-1.png" width="100%"></p>
<p>The traditional model summaries are completely dense: the point estimates <span class="math inline"><em>β̂</em></span> are nonzero for <em>all</em> covariates. By comparison, the point estimates from the smallest acceptable subset are sparse, with only 5 active coefficients. Both sets of posterior summaries track the true coefficients reasonably well.</p>
<p>Additional documentation and examples are available at <a href="https://drkowal.github.io/BayesSubsets/" class="uri">https://drkowal.github.io/BayesSubsets/</a>.</p>
</div>
</div>
  </main><aside class="col-md-3"><div class="links">
<h2 data-toc-skip>Links</h2>
<ul class="list-unstyled">
<li><a href="https://github.com/drkowal/BayesSubsets/" class="external-link">Browse source code</a></li>
<li><a href="https://github.com/drkowal/BayesSubsets/issues" class="external-link">Report a bug</a></li>
</ul>
</div>

<div class="license">
<h2 data-toc-skip>License</h2>
<ul class="list-unstyled">
<li><a href="https://www.r-project.org/Licenses/GPL-2" class="external-link">GPL-2</a></li>
</ul>
</div>


<div class="citation">
<h2 data-toc-skip>Citation</h2>
<ul class="list-unstyled">
<li><a href="authors.html#citation">Citing BayesSubsets</a></li>
</ul>
</div>

<div class="developers">
<h2 data-toc-skip>Developers</h2>
<ul class="list-unstyled">
<li>Dan Kowal <br><small class="roles"> Author, maintainer, copyright holder </small> <a href="https://orcid.org/0000-0003-0917-3007" target="orcid.widget" aria-label="ORCID" class="external-link"><span class="fab fa-orcid orcid" aria-hidden="true"></span></a> </li>
</ul>
</div>



  </aside>
</div>


    <footer><div class="pkgdown-footer-left">
  <p></p>
<p>Developed by Dan Kowal.</p>
</div>

<div class="pkgdown-footer-right">
  <p></p>
<p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.0.7.</p>
</div>

    </footer>
</div>

  

  

  </body>
</html>
